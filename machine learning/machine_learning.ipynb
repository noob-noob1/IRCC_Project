{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Forecasting Notebook\n",
    "\n",
    "This notebook is generated from machine_learning.py and is split into multiple cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from prophet import Prophet\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import xgboost as xgb\n",
    "from statsmodels.tsa.arima.model import ARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     REF_DATE                        GEO  Number_of_Households  \\\n",
      "0  1986-01-01                    Alberta                859000   \n",
      "1  1986-01-01           British Columbia               1132000   \n",
      "2  1986-01-01                   Manitoba                392000   \n",
      "3  1986-01-01              New Brunswick                237000   \n",
      "4  1986-01-01  Newfoundland and Labrador                161000   \n",
      "\n",
      "   Housing completions  Housing starts  Housing under construction  \\\n",
      "0           662.000000      603.000000                 1125.000000   \n",
      "1          1304.333333     1515.666667                 3114.666667   \n",
      "2           426.333333      536.000000                 1382.000000   \n",
      "3           329.666667      105.666667                  488.333333   \n",
      "4           181.000000       74.333333                 1009.333333   \n",
      "\n",
      "   House only NHPI  Land only NHPI  Total (house and land) NHPI  \n",
      "0             28.0            22.5                         26.4  \n",
      "1             79.5            49.2                         66.3  \n",
      "2             37.7            26.9                         34.7  \n",
      "3             75.1            56.1                         70.5  \n",
      "4             39.4            35.3                         38.7  \n"
     ]
    }
   ],
   "source": [
    "file_path = 'Trimmed_Time_Series_Data.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Read CSV and filter data for Canada (index % 9 == 8)\n",
    "# df_subset = df[df.index % 9 == 8].iloc[:, :]\n",
    "\n",
    "df_subset = df.copy()\n",
    "df_subset.reset_index(drop=True, inplace=True)\n",
    "print(df_subset.head())\n",
    "# df_subset.to_csv('Trimmed_Time_Series_Data_Canada.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare DataFrame for Prophet by renaming \"REF_DATE\" to \"ds\" and converting to datetime\n",
    "df_prophet = df_subset.rename(columns={\"REF_DATE\": \"ds\"})\n",
    "df_prophet[\"ds\"] = pd.to_datetime(df_prophet[\"ds\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use only one target variable from column index 2\n",
    "target_columns = list(df_prophet.columns[2:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_features(df, n_lags=3):\n",
    "    \"\"\"\n",
    "    Create simple lag features and a month feature.\n",
    "    Assumes df has columns 'ds' and 'y'.\n",
    "    \"\"\"\n",
    "    df_features = df.copy()\n",
    "    for lag in range(1, n_lags+1):\n",
    "        df_features[f'lag_{lag}'] = df_features['y'].shift(lag)\n",
    "    df_features['month'] = df_features['ds'].dt.month\n",
    "    df_features.dropna(inplace=True)\n",
    "    return df_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "00:35:31 - cmdstanpy - INFO - Chain [1] start processing\n",
      "00:35:31 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE Summary for each model:\n",
      "                           Prophet  Random Forest       XGBoost         ARIMA\n",
      "Number_of_Households  3.673162e+06          876.0  12084.226042  3.627858e+06\n"
     ]
    }
   ],
   "source": [
    "holdout_period = 30  # e.g., predicting 30 months ahead\n",
    "n_lags = 3         # number of lag features for ML models\n",
    "\n",
    "results = {}\n",
    "\n",
    "for target in target_columns:\n",
    "    results[target] = {}\n",
    "    df_target = df_prophet[[\"ds\", target]].rename(columns={target: \"y\"})\n",
    "    \n",
    "    # Prophet\n",
    "    train_prophet = df_target.iloc[:-holdout_period]\n",
    "    test_prophet  = df_target.iloc[-holdout_period:]\n",
    "    prophet_model = Prophet(daily_seasonality=False, weekly_seasonality=False)\n",
    "    prophet_model.fit(train_prophet)\n",
    "    future = prophet_model.make_future_dataframe(periods=holdout_period, freq='MS')\n",
    "    forecast = prophet_model.predict(future).tail(holdout_period)\n",
    "    prophet_mae = mean_absolute_error(test_prophet['y'], forecast['yhat'])\n",
    "    results[target]['Prophet'] = prophet_mae\n",
    "\n",
    "    # Random Forest / XGBoost\n",
    "    df_ml = create_features(df_target, n_lags=n_lags)\n",
    "    train_ml = df_ml.iloc[:-holdout_period]\n",
    "    test_ml = df_ml.iloc[-holdout_period:]\n",
    "    X_train = train_ml.drop(['ds', 'y'], axis=1)\n",
    "    y_train = train_ml['y']\n",
    "    X_test  = test_ml.drop(['ds', 'y'], axis=1)\n",
    "    y_test  = test_ml['y']\n",
    "    \n",
    "    rf_model = RandomForestRegressor()\n",
    "    rf_model.fit(X_train, y_train)\n",
    "    rf_pred = rf_model.predict(X_test)\n",
    "    results[target]['Random Forest'] = mean_absolute_error(y_test, rf_pred)\n",
    "    \n",
    "    xgb_model = xgb.XGBRegressor(objective='reg:squarederror')\n",
    "    xgb_model.fit(X_train, y_train)\n",
    "    xgb_pred = xgb_model.predict(X_test)\n",
    "    results[target]['XGBoost'] = mean_absolute_error(y_test, xgb_pred)\n",
    "    \n",
    "    # ARIMA\n",
    "    train_arima = df_target.iloc[:-holdout_period]\n",
    "    test_arima  = df_target.iloc[-holdout_period:]\n",
    "    arima_model = ARIMA(train_arima['y'], order=(1,1,1))\n",
    "    arima_fit = arima_model.fit()\n",
    "    forecast_arima = arima_fit.forecast(steps=holdout_period)\n",
    "    forecast_df = test_arima.copy()\n",
    "    forecast_df['yhat'] = forecast_arima.values\n",
    "    results[target]['ARIMA'] = mean_absolute_error(test_arima['y'], forecast_df['yhat'])\n",
    "\n",
    "# Print consolidated results\n",
    "results_df = pd.DataFrame(results).T\n",
    "print(\"MAE Summary for each model:\")\n",
    "print(results_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest model saved as rf_model.pkl\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# Assuming rf_model has been trained on your dataset\n",
    "with open(\"rf_model.pkl\", \"wb\") as f:\n",
    "    pickle.dump(rf_model, f)\n",
    "    \n",
    "print(\"Random Forest model saved as rf_model.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
